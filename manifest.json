{
  "manifest_version": 3,
  "name": "ToxiGuard AI",
  "version": "1.1",
  "description": "Smart NLP extension that flags, explains, and optionally censors toxic comments in real-time.",
  "icons": {
    "16": "icons/icon48.png",
    "32": "icons/icon48.png",
    "48": "icons/icon48.png",
    "128": "icons/icon48.png"
  },
  "permissions": [
    "storage",
    "notifications"
  ],
  "host_permissions": [
    "<all_urls>"
  ],
  "background": {
    "service_worker": "background.js"
  },
  "content_scripts": [
    {
      "matches": ["<all_urls>"],
      "js": ["content.js"],
      "run_at": "document_idle",
      "exclude_matches": [
        "*://chrome://*",
        "*://chrome-extension://*",
        "*://moz-extension://*",
        "*://about:*"
      ]
    }
  ],
  "action": {
    "default_popup": "popup.html",
    "default_title": "ToxiGuard AI - Smart Toxicity Detection",
    "default_icon": {
      "16": "icons/icon48.png",
      "32": "icons/icon48.png",
      "48": "icons/icon48.png",
      "128": "icons/icon48.png"
    }
  },
  "commands": {
    "toggle-detection": {
      "suggested_key": {
        "default": "Alt+T"
      },
      "description": "Toggle toxic detection on/off"
    }
  },
  "web_accessible_resources": [
    {
      "resources": ["icons/*"],
      "matches": ["<all_urls>"]
    }
  ]
}