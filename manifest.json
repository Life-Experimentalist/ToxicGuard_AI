{
    "manifest_version": 3,
    "name": "Toxic Shield",
    "version": "1.0",
    "description": "Detect and censor toxic content in real-time using ML",
    "permissions": [
        "activeTab",
        "storage",
        "scripting",
        "webNavigation",
        "tabs"
    ],
    "host_permissions": [
        "<all_urls>"
    ],
    "action": {
        "default_popup": "popup.html",
        "default_icon": {
            "16": "icons/icon16.png",
            "32": "icons/icon32.png",
            "48": "icons/icon48.png",
            "128": "icons/icon128.png"
        }
    },
    "content_scripts": [
        {
            "matches": [
                "<all_urls>"
            ],
            "js": [
                "lib/tensorflow/tf.min.js",
                "lib/tensorflow/toxicity.min.js",
                "content.js"
            ]
        }
    ],
    "web_accessible_resources": [
        {
            "resources": [
                "lib/tensorflow/*"
            ],
            "matches": [
                "<all_urls>"
            ]
        }
    ],
    "background": {
        "service_worker": "background.js"
    },
    "icons": {
        "16": "icons/icon16.png",
        "32": "icons/icon32.png",
        "48": "icons/icon48.png",
        "128": "icons/icon128.png"
    }
}